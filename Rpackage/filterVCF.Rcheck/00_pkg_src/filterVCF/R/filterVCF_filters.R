# ==========================================================================
#             Create filter functions
# ==========================================================================


#' Create filter from the INFO field
#' 
#' The function create a logical filter of the length of the vcf
#' according to the INFO field of the vcf. This is based on GATK 3.8
#' specifications.
#' 
#' The INFO field will probable not be updated by other programs when working 
#' on a vcf file. Therefore it is better to use this filter with vcf generated by GATK.
#'
#' 
#' @param vcf A vcfR object
#' @param element Which element from the INFO filed to retrieve. e.g MQ or FS
#' @param rule How to filter the sites. This follow GATK syntax. e.g "<40" will filter sites with a value lower than 40
#' @param ... list of options in the form a list object: opt. Only opt$verbose
#' is used here. Default is true.
#' @return %% logical vector of sizes length(vcf) with sites not passing rule as TRUE
#' @note %% further notes
#' @author %% Benjamin Laenen
#' @seealso %% objects to See Also as \code{\link{help}},
#' @references %% 
#' @keywords ~filters ~GATK
#' @family filters
#' @examples
#' 
#' ##opt <- list(verbose=TRUE)
#' ##filter <- create_filter_META(vcf, element = "MQ", rule = "<40", opt)
#' ##sum(filter)
#' 
#' 
#' @export
#' @importFrom vcfR extract.info
create_filter_META <- function(vcf, element, rule=NULL, ...){
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}
	if(is.null(rule)){
		return(NULL)
	}else{
		if(opt$verbose) message(sprintf("Apply filter to INFO field : %s with rule %s", element, rule), appendLF=TRUE)
		META_info <- extract.info(vcf, element, as.numeric = TRUE)
		#filter <- eval(parse(text=paste0(paste("META_info", rule, collapse = " | "), "| is.na(META_info)")))
		filter <- eval(parse(text=paste0(paste("META_info", rule, collapse = " | "))))
		filter[is.na(filter)] <- FALSE
		return(filter)
	}
}



#' Create a filter for fixed heterozygous
#' 
#' The function will create a logical filter the same length as the vcf with
#' sites that are fixed heterozygous or all heterozygous and missing.
#' 
#' 
#' 
#' @param gt genotype matrix created with extract.gt or extract_gt_ff
#' @param ... list of options in the form a list object: opt. Only opt$verbose
#' @return logical vector of sizes nrow(gt) with sites not passing the filter as TRUE
#' @inherit create_filter_META return
#' @note  ~~further notes~~ 
#' @author  ~~Benjamin Laenen~~
#' @seealso  objects to See Also as \code{\link{help}}, 
#' @references  
#' @keywords ~filter
#' @family filters
#' @examples
#' 
#' ##opt <- list(verbose=TRUE)
#' ##filter <- create_filter_fix_het(gt, opt)
#' ##sum(filter)
#' 
#' @export
#' @import bit ff ffbase
create_filter_fix_het <- function(gt, ...){
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}

	if(opt$verbose) message(sprintf("Apply filter for fix heterozygotes"), appendLF=TRUE)
	if(class(gt) == "ffdf"){
		filter <- rowSums(sapply(1:ncol(gt), function(x) create_index_ff(gt[x], "==1| == -9"))) == ncol(gt)
	}else{
		if(is.numeric(gt[1])){
			filter 	<- rowSums(gt == 1  | gt == "^./." | gt == "^.|." , na.rm = TRUE) == ncol(gt)
		}else{
			filter 	<- rowSums(gt == "^0/1" | gt == "^1/0" | gt == "^0|1" | gt == "^1|0" | gt == "^./." | gt == "^.|." , na.rm = TRUE) == ncol(gt)
		}
	}
	return(filter)
}



#' Create a filter for all heterozygous sites
#' 
#' The function will create a logical filter the same length as the vcf with
#' all heterozygous sites or all heterozygous and missing. This must be used
#' with care as it can biased the resulting data. This is indetended for haploid
#' to catch wrongly mapped reads.
#' 
#' 
#' @inheritParams create_filter_fix_het
#' @return logical vector of sizes nrow(gt) with sites not passing the filter as TRUE
#' @inherit create_filter_META return
#' @note  ~~further notes~~ 
#' @author  ~~Benjamin Laenen~~
#' @seealso  objects to See Also as \code{\link{help}}, 
#' @references  
#' @keywords filter
#' @family filters
#' @examples
#' 
#' ##opt <- list(verbose=TRUE)
#' ##filter <- create_filter_all_het(gt, opt)
#' ##sum(filter)
#' 
#' @export
create_filter_all_het <- function(gt, ...){
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}

	if(opt$verbose) message(sprintf("Apply filter to remove all heterozygotes sites, this is risky, make sure you know what you are doing. For example suitable for haploid or highly selfing species."), appendLF=TRUE)
	if(class(gt) == "ffdf"){
		filter <- rowSums(sapply(1:ncol(gt), function(x) create_index_ff(gt[x], "==1| == -9"))) >=1
	}else{
		if(is.numeric(gt[1])){
			filter 	<- rowSums(gt == 1  , na.rm = TRUE) >= 1
		}else{
			filter 	<- rowSums(gt == "^0/1" | gt == "^1/0" | gt == "^0|1" | gt == "^1|0"  , na.rm = TRUE) >=1
		}
	}
	return(filter)
}



#' Create a filter for missing data
#' 
#' The function create a filter with sites that have more than the specified
#' percent of missing genotypes per sites.
#' 
#' 
#' 
#' @param gt Either a genotype matrix created with extract.gt or extract_gt_ff OR a vcfR object. If a vcfR is provided extract_gt_ff is run internally.
#' @param ... list of options in the form a list object: opt. Only opt$verbose
#' @param allowed_missing_threshold Allowed proportion of missing genotype. Default is 0.2
#' @return logical vector of sizes nrow(gt) with sites not passing the filter as TRUE
#' @note  ~~further notes~~ 
#' @author  ~~Benjamin Laenen~~
#' @seealso  objects to See Also as \code{\link{help}}, 
#' @references  
#' @keywords filter
#' @family filters
#' @examples
#' 
#' ##opt <- list(verbose=TRUE)
#' ##filter <- create_filter_missing(gt, allowed_missing_threshold = 0.2, opt)
#' ##sum(filter)
#' 
#' @export
#' @import vcfR
create_filter_missing <- function(gt, allowed_missing_threshold = 0.2, ...){
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}

	if(opt$verbose) message(sprintf("Apply filter allowing maximum %s missing proportion", allowed_missing_threshold), appendLF=TRUE)
	if(class(gt) == "vcfR"){
		gt <- extract_gt_ff(gt)
	}
	if(class(gt) == "ffdf"){
		filter <- rowSums(sapply(1:ncol(gt), function(x) create_index_ff(gt[x], "== -9"))) / ncol(gt) > allowed_missing_threshold
	}else{
		filter 	<- (rowSums(gt == "./." | gt == ".|.") / ncol(gt)) > allowed_missing_threshold
	}
	return(filter)
}



#' Create filter with indel
#' 
#' The function uses the REF and ALT field from the vcf to detect indels.
#' Indels are detected if either of the two fields contains more than one base
#' or if there is a * in the field (compatibility with GATK >3.8).
#' 
#' 
#' @inheritParams create_filter_META
#' @return logical vector of sizes length(vcf) with indel sites as TRUE
#' @note  ~~further notes~~ 
#' @author  ~~Benjamin Laenen~~
#' @seealso  objects to See Also as \code{\link{help}}, 
#' @references  
#' @keywords filter
#' @family filters
#' @examples
#' 
#' ##opt <- list(verbose=TRUE)
#' ##filter <- create_indel_filter(vcf, allowed_missing_threshold = 0.2, opt)
#' ##sum(filter)
#' 
#' @export
#' @importFrom vcfR getALT getREF
create_indel_filter <- function(vcf, ...){
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}
	if(opt$verbose) message(sprintf("Apply filter for indels"), appendLF=TRUE)
	ALT <- getALT(vcf)
	REF <- getREF(vcf)
	#some allele can be A,C in the ALT and this is not an indel
	#We count any allele is larger than 1bp and use it as additional rule to
	#create the filter
	max_size_of_allele <- sapply(strsplit(ALT, ","), function(x) max(nchar(x))) == 1
	max_size_of_allele_REF <- sapply(strsplit(REF, ","), function(x) max(nchar(x))) == 1

	indel_filter <- (grepl("\\*", ALT) | grepl("\\*", REF) | !max_size_of_allele | !max_size_of_allele_REF)
	return(indel_filter)
}



#' Create filter for invariant
#' 
#' This function check the vcf for invariant sites. Invariant sites are either
#' sites that have a "." in the ALT field or if a genotype matrix is given sites
#' that are all homozygous for the reference allele or all homozygous for the
#' reference allele and missing. In practice it can be used to separate SNPs
#' from invariant.
#' 
#' 
#' @inheritParams create_filter_META
#' @inheritParams create_filter_fix_het
#' @return logical vector of sizes length(vcf) with indel sites as TRUE
#' @note  ~~further notes~~ 
#' @author  ~~Benjamin Laenen~~
#' @seealso  objects to See Also as \code{\link{help}}, 
#' @references  
#' @keywords filter
#' @family filters
#' @examples
#' 
#' ##opt <- list(verbose=TRUE)
#' ##filter <- create_invariant_filter(vcf, opt)
#' ##vcf_snp <- vcf[!filter]
#' ##vcf_inv <- vcf[filter]
#' ##gt <- extract_gt_ff(vcf_snp)
#' ##filter_invariant_from_genotype <- create_invariant_filter(vcf_snp,gt = gt, opt)
#' ##sum(filter)
#' ##sum(filter_invariant_from_genotype)
#' 
#' @export
create_invariant_filter <- function(vcf, gt = NULL, ...){
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}

	if(opt$verbose) message(sprintf("Apply filter for invariant"), appendLF=TRUE)
	ALT <- getALT(vcf)
	filter_invariant <- ALT == "."

	if(!is.null(gt)){
		if(class(gt) == "ffdf"){
			filter_invariant_by_gt <- rowSums(sapply(1:ncol(gt), function(x) create_index_ff(gt[x], "==0| == -9"))) == ncol(gt)
		}else{
			filter_invariant_by_gt <- rowSums(gt == "0/0" | gt == "0|0" | gt == "./." | gt == ".|.") == ncol(gt)
		}
		filter_invariant <- filter_invariant | filter_invariant_by_gt
	}
	gc(reset=TRUE)
	return(filter_invariant)
}


#' Filter fixed sites
#' 
#' Create a logical vector of the size of @gt with sites that are fixed in the
#' populations or fixed and missing
#' 
#' 
#' 
#' @inheritParams create_filter_fix_het
#' @return logical vector of sizes nrow(gt) with fixed sites as TRUE
#' @note  ~~further notes~~ 
#' @author  ~~Benjamin Laenen~~
#' @seealso  objects to See Also as \code{\link{help}}, 
#' @references  
#' @keywords ~filter
#' @family filters
#' @examples
#' 
#' ##opt <- list(verbose=TRUE)
#' ##filter <- create_filter_fixed_sites(gt, opt)
#' ##sum(filter)
#' 
#' @export
create_filter_fixed_sites <- function(gt, ...){
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}
	
	if(opt$verbose) message(sprintf("Apply filter for fixed invariant\n"), appendLF=TRUE)
	if(class(gt) == "ffdf"){
		filter_fixed_sites <- rowSums(sapply(1:ncol(gt), function(x) create_index_ff(gt[x], "==2| == -9"))) == ncol(gt)
	}else{
		filter_fixed_sites <- rowSums(gt == "1/1" | gt == "1|1" | gt == "./." | gt == ".|.") == ncol(gt)
	}
	return(filter_fixed_sites)
}



#' Create filter for percentage of repeats in windows
#' 
#' The function is intented to remove windows in the genome with more than a
#' percentage of sites consiting of repeats. In practice the bed file defining
#' the intervals to consider can be any bedfile. For example a bedfile defining
#' TE can be used to detect windows with a certain percentage of TE.
#' 
#' 
#' @param reference The path to the reference genome or a DNAStringSet object with the reference.
#' @param repeat_bed_file The path to the bedfile or a GRanges object
#' @param windows_size Size of fixed windows
#' @param threshold The percentage above which the window is reported in the filter.
#' @inheritParams create_filter_META
#' @return A GRanges object with the windows to remove (not passing the threshold)
#' @note  ~~further notes~~ 
#' @author  ~~Benjamin Laenen~~
#' @seealso  objects to See Also as \code{\link{help}}, 
#' @references  
#' @keywords filter
#' @family filters
#' @examples
#' 
#' ##opt <- list(verbose=TRUE)
#' ##reference <- "Crubella.fa"
#' ##repeat_bed_file <- "repeats.bed"
#' ##filter <- create_filter_repeats_in_windows(reference, repeat_bed_file, vcf, windows_size=20000, threshold=0.5, opt)
#' ##sum(width(filter))
#' 
#' ##reference <- readDNAStringSet("Crubella.fa")
#' ##repeat_bed_file <- bed2Grange("repeats.bed")
#' ##filter <- create_filter_repeats_in_windows(reference, repeat_bed_file, vcf, windows_size=20000, threshold=0.5, opt)
#' ##sum(width(filter))
#' 
#' @export
#' @import Biostrings
create_filter_repeats_in_windows <- function(reference, repeat_bed_file, vcf, windows_size=20000, threshold=0.5, ...){
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}
	
	if(opt$verbose) message(sprintf("Apply filter for repeats in windows %sbp with a threshold of %s", windows_size, threshold), appendLF=TRUE)
	# This function create windows for the refrence and counts
	# the percentage of bp covered by repeats (can be any the bed file)
	# , if it is higher than the thresholds it returns the windows
	# to remove
	windows_genome <- windows_from_reference(reference, vcf, windows_size = windows_size)

	if(class(repeat_bed_file) == "GRanges"){
		repeats <- repeat_bed_file
	}else{
		repeats <- bed2Grange(repeat_bed_file)
	}
	repeats_in_windows <- lapply(seq_along(windows_genome), function(i) findOverlaps(repeats, windows_genome[[i]], minoverlap=1, ignore.strand=TRUE))

	percentage_windows_as_repeats <- lapply(repeats_in_windows, function(y) (tapply(y@from, y@to, function(x) sum(width(repeats[x]))) / windows_size) > threshold)
	#percentage_windows_as_repeats <- (tapply(repeats_in_windows[[1]]@from, repeats_in_windows[[1]]@to, function(x) sum(width(repeats[x]))) / windows_size) > threshold

	windows_with_half_repeats_to_remove <-lapply(seq_along(windows_genome), function(i) windows_genome[[i]][as.numeric(names(percentage_windows_as_repeats[[i]][percentage_windows_as_repeats[[i]] == TRUE]))])

	windows_with_half_repeats_to_remove <- unlist(as(windows_with_half_repeats_to_remove, "GRangesList"))
	return(reduce(windows_with_half_repeats_to_remove))
}



#' Create a filter using small scale normalized DP
#' 
#' These filters are designed to try to deal with repetitive genome. Region
#' with repeats will often have higher depth due to read mapping to two or more
#' regions. We use short windows (recommended between 1000 and 5000) to
#' calculate the depth for each samples for each snps in the VCFfile. The depth
#' is nomralized for each sample by the median depth over all snps. This enable
#' to compare samples with different coverage and apply relative threshold
#' instead of raw value of depth. Then two kind of rules are applied. First a
#' windows is removed if the mean normalized depth is higher than the threshold
#' and the mean upper 95 quartile is above the CI threshold. For example if the
#' a sample has median depth of 30X, a windows with 60X and a 95 quartile of 90X
#' will have a normalized median depth of 2 and 95 quartile of 3. Taking the
#' mean over samples for this windows might give an value of normalized median
#' depth of 2.2 and 95 quartile of 3.2. We than apply the threshold (typically 2
#' and 4) 2.2 > 2 or 3.2 > 4, hence the snps in this windows are filtered. The
#' second rule is more stringent and remove a windows if any sample is over the
#' thresholds for a windows. The pipeline use the first rule with the first
#' value specified in the option --filter_high_DP_standardized#'
#' 
#' 
#' 
#' @inheritParams create_filter_repeats_in_windows
#' @param threshold = 2 value(s) for the median normalized DP threshold
#' @param threshold_CI = 4 value(s) for the 95 quartile normalized DP threshold
#' @param overlapping=1000 sliding window parameter
#' @param percent_passing_filter = 0.95 determine the percentage of samples required to pass the threshold of normalized coverage to call the windows as rejected
#' @return a list of logical filter of length @vcf
#' @author  ~~Benjamin Laenen~~
#' @references  
#' @keywords filter
#' @family filters
#' @examples
#' 
#' ##opt <- initialise_option()
#' ##reference <- "Crubella.fa"
#' ##repeat_bed_file <- "repeats.bed"
#' ##filter <- create_filter_high_DP_standardized(reference, vcf, threshold = 2, threshold_CI = 4, windows_size=1000, overlapping=1000, opt)
#' ##sum(width(filter))
#' 
#' ##reference <- readDNAStringSet("Crubella.fa")
#' ##repeat_bed_file <- bed2Grange("repeats.bed")
#' ##filter <- create_filter_high_DP_standardized(reference, vcf, threshold = 2, threshold_CI = 4, windows_size=1000, overlapping=1000, opt)
#' ##sum(width(filter))
#' 
#' @export
create_filter_high_DP_standardized <- function(reference, vcf, 	threshold = 2, threshold_CI = 4, windows_size=1000, overlapping=1000, percent_passing_filter = 0.95, ...){
	#function to replace the previous pipeline to remove
	#regions of wrongly mapped read in repeats in Arabis alpina
	#it use the information on coverage on a small scale
	#standtardize it and compare across sample to detect region
	#where coverage is out of the norm probably because of repeats.
	# Converting vcf to Grange
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}
	
	if(opt$verbose) message(sprintf("\nApply filter for high DP across samples in windows of %sbp with a slidding of %sbp and apply threshold of median : %s and  CI : %s", windows_size,overlapping, threshold, threshold_CI), appendLF=TRUE)
	vcf_bed_GRange <- vcf2Grange(vcf)

	#creating the slidding windows
	overlapping_5k_windows <- windows_from_reference(reference, vcf, windows_size, overlapping)

	# Add the depth as value to the bed file for the vcf,
	# they are ordered so we can merge them without problem
	dp <- extract.gt(vcf, element="DP", as.numeric=TRUE)
	dp[dp==0] <- NA
	values(vcf_bed_GRange) <- dp

	#intersect with the snps and find which snps is in which windows
	overlap_vcf_5kb_sliding <- findOverlaps(vcf_bed_GRange, overlapping_5k_windows[[1]], minoverlap=1, ignore.strand=TRUE)

	#for each windows calculating the median coverage per individual and the 95 quantile
	median_CI_per_windows <- tapply(overlap_vcf_5kb_sliding@from, overlap_vcf_5kb_sliding@to, function(x) sapply(values(vcf_bed_GRange[x]), quantile, probs = c(0.5, 0.95), na.rm = TRUE))
 	# adding the windows with no overlap that were drop during the intersection
 	names(median_CI_per_windows) <- unique(overlap_vcf_5kb_sliding@to)
	all_windows <- as.character(seq_len(length(overlapping_5k_windows[[1]])))
 	index_missing_windows <-  all_windows [!(all_windows %in% unique(overlap_vcf_5kb_sliding@to))]

 	# filling the missing windows with fake NA values the same size as the other (nb of individuals)
 	median_CI_per_windows[index_missing_windows] <- list(matrix(NA, nrow = 2, ncol = ncol(dp)))
	#reordering them to be able to easilly subset the original 5kb windows
	median_CI_per_windows <- median_CI_per_windows[order(as.numeric(names(median_CI_per_windows)))]

	#transforming the format to have a list of individual with median
	#an CI value for each windows
	median_CI_per_ind <- list()
	for(i in seq_len(ncol(dp))){
		median_CI_per_ind[[i]] <- t(sapply(median_CI_per_windows, function(x) x[,i]))
	}

	#Standardize the coverage by dividing by the median over windows for each
	#individuals
	standardized_median_CI_per_ind <- lapply(median_CI_per_ind, function(x) x / median(x[,1], na.rm = TRUE))

	# plot(density(standardized_median_CI_per_ind[[6]][,1], na.rm =TRUE), col = sample(rainbow(300),1))
	# for(i in 1:282){
	# 	try(lines(density(standardized_median_CI_per_ind[[i]][,1], na.rm =TRUE), col = sample(rainbow(300),1), xlim =c(0,4)))
	# }
	#Set the number/pc of samples 
	nb_sample <- length(standardized_median_CI_per_ind)
	five_pc_thr <- nb_sample * percent_passing_filter
	
	if(length(threshold)>1){
		# For each individual testing is the value exceed the threshold
		data_threshold <- lapply(threshold, function(thr) lapply(standardized_median_CI_per_ind, function(x) x[,1] > thr & !is.na(x[,1]) | x[,2] > threshold_CI & !is.na(x[,2])))
		# Summing over all individual and remove a windows if any individual was
		# above the threshold, this can lead to a lot of windows removed
		# the other methods below is prefered.
		#index_window_fail_filter  <- lapply(data_threshold, function(x)Reduce("+", x) > 0)
		
		# remove if more than 5% of the samples are above the threshold
		# this is a bit less strict and avoid one odd sample driving
		# the filtering
		index_window_fail_filter  <- lapply(data_threshold, function(x)Reduce("+", x) < five_pc_thr)

		#creating a Grange object with the windows to remove
		total_high_DP_windows <- lapply(index_window_fail_filter, function(x) overlapping_5k_windows[[1]][x])
		total_high_DP_windows <- lapply(total_high_DP_windows, reduce)
	}else{
		# For each individual testing is the value exceed the threshold
		data_threshold <- lapply(standardized_median_CI_per_ind, function(x) x[,1] > threshold & !is.na(x[,1]) | x[,2] > threshold_CI & !is.na(x[,2]))
		# Summing over all individual and remove a windows if 5% of the sample are
		# above the threshold, to avoid removing too many if an odd sample is maong the population

		# the other methods below is prefered but comparison have to be made.
		index_window_fail_filter  <- Reduce("+", data_threshold) < five_pc_thr

		#creating a Grange object with the windows to remove
		total_high_DP_windows <- overlapping_5k_windows[[1]][index_window_fail_filter]
		total_high_DP_windows <- reduce(total_high_DP_windows)
	}

	#Second approach. A window is removed if consistently above the threshold across samples.
	#First taking the mean over all individual for each windows before removing window.
	#binding all individual together and selction column for median and CI
	tmp <- do.call("cbind", standardized_median_CI_per_ind)
	median_across <- tmp[,grep("50", colnames(tmp))]
	CI_across <- tmp[,grep("95", colnames(tmp))]

	# Taking the mean over individuals for each windows
	mean_of_median_accros_samples <- rowMeans(median_across, na.rm =TRUE)
	mean_of_CI_accros_samples <- rowMeans(CI_across, na.rm =TRUE)

	if(length(threshold)>1){
		#applying the rules to select the windows to remove
		high_DP_windows_means_across_sample <- lapply(threshold, function(thr) overlapping_5k_windows[[1]][mean_of_median_accros_samples > thr  & !is.na(mean_of_median_accros_samples) | mean_of_CI_accros_samples > threshold_CI & !is.na(mean_of_CI_accros_samples)])

		#merging the Grange object into non overlapping windows
		high_DP_windows_means_across_sample <- lapply(high_DP_windows_means_across_sample, reduce)
		return(list(high_DP_windows_means_across_sample=as.list(high_DP_windows_means_across_sample), total_high_DP_windows=as.list(total_high_DP_windows)))
	}else{
		#applying the rules to select the windows to remove
		high_DP_windows_means_across_sample <- overlapping_5k_windows[[1]][mean_of_median_accros_samples > threshold  & !is.na(mean_of_median_accros_samples) | mean_of_CI_accros_samples > threshold_CI & !is.na(mean_of_CI_accros_samples)]

		#merging the Grange object into non overlapping windows
		high_DP_windows_means_across_sample <- reduce(high_DP_windows_means_across_sample)
		return(list(high_DP_windows_means_across_sample=high_DP_windows_means_across_sample, total_high_DP_windows=total_high_DP_windows))
	}

}



#' Create a fiter based on heterozygous sites in samples
#' 
#' This function removes fixed heterozygous sites (i.e. all individuals are
#' 0/1 for the sites) in a suite samples if those sites are in clustering
#' together. '   If at least 3 fixed heterozygous sites in the samples are
#' present in 10bp windows '   then the window is removed. This is another
#' filter intented '   to remove region with high repeats contents because fixed
#' heterozygous sites will '   likely be in small cluster (observed in IGV) if
#' coming from '   wrongly map reads. In order to identify the true wrongly map
#' read from legitimate fixed heterozygous the filter needs to be based on a
#' population that is expected to have very low level of heterozygosity. Highly
#' inbred or bottlenecked population could be used as the level of fixed
#' heterozygous is expected to be low and it is unlikely that if they are
#' present there will be clustering together.
#'
#' This was especially designed for Arabis alpina
#' with the Swedish population as reference pop as they should have
#' much less fixed heterozygous sites being selfers.
#' 
#' Note of caution. Balancing selection could produce a pattern where a sites
#' is fixed for 2 alleles and can be trapped by this filter.
#' 
#' @inheritParams create_filter_fix_het
#' @param vcf If the genotype is provided as ffdf, the vcfR object that what used to generate the matrix must be provided to extract the position. If not the vcf is not needed.
#' @param pop_pattern A regular expression to grep the names of the sample in the colnames of the genotype matrix. It can be a single pattern as "pop1.+" or a list of sample names "sample1|sample2|sampleN"
#' @param windows_size The size of the windows to detect the contiguous fixed heterozygous.
#' @param max_nb_contigous_hets The maximum number of contiguous fixed heterozygous allowed in the a windows. 
#' @return GRanges object with windows with contiguous fixed heterozygous sites as TRUE
#' @author  ~~Benjamin Laenen~~
#' @seealso  objects to See Also as \code{\link{help}}, 
#' @references  
#' @keywords ~filters ~GATK
#' @family filters
#' @examples
#' 
#' ##Select some samples and create a regex pattern
#' ##sample_name <- colnames(gt)[c(1,2,5,8,6,12,15)]
#' ##sample_pattern <- paste(sample_name, collapse = "|")
#' ##filter <- create_filter_fix_het_contiguous_in_pop(gt, vcf = vcfR, pop_pattern = sample_pattern, windows_size = 10, max_nb_contigous_hets = 2)
#' ##Remove the windows from the vcf
#' ##vcf_filtered <- intersect_Granges(vcfR, filters, invert = TRUE)
#' 
#' @export
create_filter_fix_het_contiguous_in_pop <- function(gt, vcf=NULL, pop_pattern, windows_size = 10, max_nb_contigous_hets = 2, report_hit = FALSE, ...){
	#remove fix het in a pop if there are in clusters.
	#If at least 3 fix het in the pop are present in 10bp windows
	#or change this for larger windows as seens in IGV for arabis
	#50bp might make more sense
	#then the window is removed. This is another filter intented
	#to remove region with high repeats contents because fix het will
	#likely be in small cluster (obersed in IGV) if coming from
	#wrongly map reads. This is espacially designed for Arabis alpina
	#with the swedish/Abisko or Riastan pop as reference pop as they should have
	#much less fix het being selfers.
	#The function return a Grange object with windows to remove
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}
	
	if(opt$verbose) message(sprintf("Apply filter for at leat %s contiguous fix heterozygotes in pop %s in %sbp windows.\nSample retained are:\n%s",max_nb_contigous_hets+1, pop_pattern, windows_size, paste(grep(pop_pattern, colnames(gt), value = TRUE), collapse = "\n")), appendLF=TRUE)

	#extract samples from the pop using the pattern

	#search which snps is fix heterozygotes or fix and NA
	if(class(gt) == "ffdf"){
		sw <- gt[grep(pop_pattern, colnames(gt))]
		index_fix_het_sw <- rowSums(sapply(1:ncol(sw), function(x) create_index_ff(sw[x], "==1| == -9"))) >= ncol(sw)
		pos_fix_het <- getPOS(vcf[index_fix_het_sw])
		chr <- getCHROM(vcf)[1]
	}else{
		sw <- gt[,grep(pop_pattern, colnames(gt))]
		index_fix_het_sw  <- which (rowSums(sw == "^1|0" | sw == "^0|1" |sw == "^1/0" | sw == "^0/1" | sw == "^./.", na.rm =TRUE) >=ncol(sw))
		#extract the position (note that this only works for one chromosome at the time)
		pos_fix_het <- rownames(sw[index_fix_het_sw,])
		#extract chromose name (note not checking if multiple only looking at the first row)
		chr <- gsub("(.+)_.+", "\\1", rownames(gt)[1])
		pos_fix_het <- as.numeric(gsub(paste0(chr, "_"), "", pos_fix_het))
	}

	#find how many snps are in 10bp windows
	pos_fix_het_in_10bp <- cut(pos_fix_het, seq(1,max(pos_fix_het), by = windows_size))
	#extract the names of the windows with more than 2 fix het
	windows_contiguous_fix_het_in_10bp <- names(which(table(pos_fix_het_in_10bp) > max_nb_contigous_hets))
	nb_hits_windows_contiguous_fix_het_in_10bp <- table(pos_fix_het_in_10bp)[which(table(pos_fix_het_in_10bp) > max_nb_contigous_hets)]
	if(length(windows_contiguous_fix_het_in_10bp) > 0){
		windows_contiguous_fix_het_in_10bp <- matrix(unlist(strsplit(gsub("\\(|]", "", windows_contiguous_fix_het_in_10bp), ",")), ncol = 2, byrow =TRUE)
		fix_het_pop <- GRanges(
		    seqnames=Rle(chr),
		    ranges=IRanges(as.numeric(windows_contiguous_fix_het_in_10bp[,1]), end=as.numeric(windows_contiguous_fix_het_in_10bp[,2]))
		)
		if(isTRUE(report_hit)){
			values(fix_het_pop)[,"hit"] <- nb_hits_windows_contiguous_fix_het_in_10bp
		}else{
			fix_het_pop <- reduce(fix_het_pop)
		}
	}else{
		fix_het_pop <- GRanges()
	}
	#create a Grange object with the windows to remove
	return(fix_het_pop)
}



#' Modify the genotype in the vcf based on depth
#' 
#' This function extract the depth of coverage for each sites and each
#' individuals and set the genotype as missing (./.) if DP is below the min or
#' above the max threshold for depth. The fied DP must be present in the FORMAT
#' column. Note that the number of missing per sites will be modified by this filters.
#' 
#' 
#' 
#' @inheritParams create_filter_repeats_in_windows
#' @param min_DP The minimum depth threshold to set genotype as missing
#' @param max_DP The minimum depth threshold to set genotype as missing
#' @return A vcfR object with genotype as missing if not passing filters.
#' @note  ~~further notes~~ 
#' @author  ~~Benjamin Laenen~~
#' @seealso  objects to See Also as \code{\link{help}}, 
#' @references  
#' @keywords ~filters ~GATK
#' @family filters
#' @examples
#' 
#' vcf_modified_dp <- change_gt_by_DP_filter(vcf, min_DP=10, max_DP=200)
#' 
#' @export
change_gt_by_DP_filter <- function(vcf, min_DP=10, max_DP=200, ...){
	#this functions alters the genotype by replacing value
	#not passing the filter by NA
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}
	
	if(opt$verbose) message(sprintf("Changing genotype  to missing if max_DP %s > DP < min_DP %s", max_DP, min_DP), appendLF=TRUE)


	dp <- extract.gt(vcf, element="DP", as.numeric=TRUE)

	dp_filter <- dp < min_DP | dp > max_DP | is.na(dp)
	rm(dp)
	gc()
	for(i in seq_len(ncol(dp_filter))){
		vcf@gt[dp_filter[,i],i+1] <- gsub("...:(.+$)", "./.:\\1", vcf@gt[dp_filter[,i],i+1])
	}

	# index_format_DP <- vcf@gt[,"FORMAT"]
	# index_format_DP <- strsplit(index_format_DP, ":")
	# index_format_DP <- sapply(index_format_DP, function(x) which(x== "DP"))

	# for(i in 2:ncol(vcf@gt)){
	# 	tmp <- strsplit(vcf@gt[,i], ":")
	# 	tmp2 <- sapply(seq_along(index_format_DP), function(j) as.numeric(tmp[[j]][index_format_DP[j]]) < min_DP | as.numeric(tmp[[j]][index_format_DP[j]]) > max_DP | is.na(as.numeric(tmp[[j]][index_format_DP[j]])))
	# 	vcf@gt[tmp2,i] <- gsub("...:(.+$)", "./.:\\1", vcf@gt[tmp2,i])
	# }

	return(vcf)
}

#' Modify the genotype in the vcf based on genotype quality
#' 
#' This function extract the genotype quality scores for each sites and each '
#' individuals and set the genotype as missing (./.) if GQ or RGQ is below the
#' min threshold for genotype quality. The fied GQ for vairant and RGQ for
#' invariant must be present in the FORMAT column. If "auto" is used for
#' threshold the 5 percent quartile is used as a lower threshold for GQ/RGQ.
#' Note that the number of missing per sites will be modified by this filters.
#' 
#' 
#' 
#' @inheritParams create_filter_repeats_in_windows
#' @param invariable If the vcf is composed of invariable sites, GATK use RGQ instead of GQ and invariable must be set to TRUE.
#' @param GQ_threshold The minimum genotype quality threshold to set genotype as missing. If "auto" set the threshold based on the 5 percent quartile over all sites
#' @return A vcfR object with genotype as missing if not passing filters.
#' @author  ~~Benjamin Laenen~~
#' @references  
#' @keywords ~filters ~GATK
#' @family filters
#' @examples
#' 
#' vcf_modified_GQ <- change_gt_by_GQ_filter(vcf, GQ_threshold=auto)
#' vcf_modified_GQ5 <- change_gt_by_GQ_filter(vcf, GQ_threshold=5)
#' 
#' vcf_modified_RGQ <- change_gt_by_GQ_filter(vcf_invariant, invariable = TRUE, GQ_threshold=5)
#' 
#' @export
change_gt_by_GQ_filter <- function(vcf, invariable = FALSE, GQ_threshold = 5, ...){
	#this functions alters the genotype by replacing value
	#not passing the filter by NA
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}
	
	if(opt$verbose) message(sprintf("Changing genotype  to missing if (R)GQ is <%s", GQ_threshold), appendLF=TRUE)

	if(isTRUE(invariable)){
		GQ <- extract.gt(vcf, element="RGQ", as.numeric=TRUE)
	}else{
		GQ <- extract.gt(vcf, element="GQ", as.numeric=TRUE)
	}

	if(GQ_threshold == "auto"){
		GQ_threshold <- quantile(GQ[GQ != 0], probs = 0.05, na.rm = TRUE)
		if(opt$verbose) message(sprintf("GQ threshold set automatically to <%s", GQ_threshold), appendLF=TRUE)
	}

	GQ_filter <- GQ <= GQ_threshold | is.na(GQ)
	rm(GQ)
	gc()
	for(i in seq_len(ncol(GQ_filter))){
		vcf@gt[GQ_filter[,i],i+1] <- gsub("...:(.+$)", "./.:\\1", vcf@gt[GQ_filter[,i],i+1])
	}

	return(vcf)
}



#' Filter for missing per individual
#' 
#' Create filters for samples with a proportion of missing data higher than
#' the threshold of allowed missing. This function can be used to detect
#' individuals with low sequencing.
#' 
#' 
#' @param gt Either a vcfR object, a genotype matrix obtained using extract.gt or extract_gt_ff
#' @return The names of the sample passing the filter
#' @note  ~~further notes~~ 
#' @author  ~~Benjamin Laenen~~
#' @seealso  objects to See Also as \code{\link{help}}, 
#' @references  
#' @keywords ~filters ~GATK
#' @family filters
#' @examples
#' 
#' sample_non_missing <- missing_per_individual(gt , allowed_missing_threshold_per_ind = 0.2)
#' vcf_non_missing <- vcf[grep(sample_non_missing, colnames(gt))]
#' 
#' @export
missing_per_individual <- function(gt, allowed_missing_threshold_per_ind = 0.2, ...){
	myDots <- list(...)
	if (!is.null(myDots$opt)){
		opt <- myDots$opt
	}else{
		opt <- parse_args(OptionParser(option_list=initialise_option()))
	}
	
	if(opt$verbose) message(sprintf("Apply filter allowing maximum %s missing per individual. They will be removed", allowed_missing_threshold_per_ind), appendLF=TRUE)
	if(class(gt) == "vcfR"){
		gt <- extract_gt_ff(gt)
	}
	if(class(gt) == "ffdf"){
		missing_pc <- colSums(sapply(1:ncol(gt), function(x) create_index_ff(gt[x], "== -9"))) / nrow(gt)
		filter <- missing_pc > allowed_missing_threshold_per_ind
	}else{
		missing_pc 	<- (colSums(gt == "./." | gt == ".|.") / nrow(gt))
		filter 	<- missing_pc > allowed_missing_threshold_per_ind
	}
	#return the names of the sample that passe the filter
	if(opt$verbose) message(sprintf("List of sample with more than %s  of missing data:\n%s", allowed_missing_threshold_per_ind, paste(colnames(gt)[filter], round(missing_pc[filter], 2), collapse= "\n")), appendLF=TRUE)
	if(sum(filter) == ncol(gt)){
		message("No samples left for analysis! Stopping")
		quit(1)	
	} 
	return(colnames(gt)[!filter])
}
